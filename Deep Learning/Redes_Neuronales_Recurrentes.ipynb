{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNvoaWTfw4y2CcvkhAz9Dgn",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/FernandoCerriteno/Portafolio-TC3007C.502/blob/main/Deep%20Learning/Redes_Neuronales_Recurrentes.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Librerias"
      ],
      "metadata": {
        "id": "srFQvzehycl7"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L4RVez_qyJTS"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "import os"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Texto utilizado - Alice in Wonderland"
      ],
      "metadata": {
        "id": "LTe-9SXUyYLe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "path_to_fileDL = tf.keras.utils.get_file('alice_in_wonderland.txt', 'https://raw.githubusercontent.com/kuemit/txt_book/master/examples/alice_in_wonderland.txt')"
      ],
      "metadata": {
        "id": "M0RcwWjXyg7E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = open(path_to_fileDL, 'rb').read().decode(encoding='utf-8')\n",
        "print('Long del texto: {} caracteres'.format(len(text)))\n",
        "\n",
        "vocab = sorted(set(text))\n",
        "print('El texto tiene {} caracteres:'.format(len(vocab)))\n",
        "print(vocab)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PH_ofB7uzLR6",
        "outputId": "59eb3243-338b-4343-c83f-cf8812da4d91"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Long del texto: 148208 caracteres\n",
            "El texto tiene 81 caracteres:\n",
            "['\\n', ' ', '!', '\"', \"'\", '(', ')', '*', ',', '-', '.', '0', '1', '2', '3', '4', '5', '6', '8', '9', ':', ';', '=', '?', '@', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', '[', ']', '_', '`', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tokenizacion del vocab e inversa"
      ],
      "metadata": {
        "id": "gWT08vET0jRU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "char2idx = {u:i for i,u in enumerate(vocab)}\n",
        "idx2char = np.array(vocab)\n",
        "\n",
        "for char,_ in zip(char2idx, range(len(vocab))):\n",
        "  print('{:4s}: {:3d}, '.format(repr(char),char2idx[char]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fVppgMj40ptb",
        "outputId": "b6a00e73-f3d2-47ad-cd24-c6e3fa37e4e8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "'\\n':   0, \n",
            "' ' :   1, \n",
            "'!' :   2, \n",
            "'\"' :   3, \n",
            "\"'\" :   4, \n",
            "'(' :   5, \n",
            "')' :   6, \n",
            "'*' :   7, \n",
            "',' :   8, \n",
            "'-' :   9, \n",
            "'.' :  10, \n",
            "'0' :  11, \n",
            "'1' :  12, \n",
            "'2' :  13, \n",
            "'3' :  14, \n",
            "'4' :  15, \n",
            "'5' :  16, \n",
            "'6' :  17, \n",
            "'8' :  18, \n",
            "'9' :  19, \n",
            "':' :  20, \n",
            "';' :  21, \n",
            "'=' :  22, \n",
            "'?' :  23, \n",
            "'@' :  24, \n",
            "'A' :  25, \n",
            "'B' :  26, \n",
            "'C' :  27, \n",
            "'D' :  28, \n",
            "'E' :  29, \n",
            "'F' :  30, \n",
            "'G' :  31, \n",
            "'H' :  32, \n",
            "'I' :  33, \n",
            "'J' :  34, \n",
            "'K' :  35, \n",
            "'L' :  36, \n",
            "'M' :  37, \n",
            "'N' :  38, \n",
            "'O' :  39, \n",
            "'P' :  40, \n",
            "'Q' :  41, \n",
            "'R' :  42, \n",
            "'S' :  43, \n",
            "'T' :  44, \n",
            "'U' :  45, \n",
            "'V' :  46, \n",
            "'W' :  47, \n",
            "'X' :  48, \n",
            "'Y' :  49, \n",
            "'Z' :  50, \n",
            "'[' :  51, \n",
            "']' :  52, \n",
            "'_' :  53, \n",
            "'`' :  54, \n",
            "'a' :  55, \n",
            "'b' :  56, \n",
            "'c' :  57, \n",
            "'d' :  58, \n",
            "'e' :  59, \n",
            "'f' :  60, \n",
            "'g' :  61, \n",
            "'h' :  62, \n",
            "'i' :  63, \n",
            "'j' :  64, \n",
            "'k' :  65, \n",
            "'l' :  66, \n",
            "'m' :  67, \n",
            "'n' :  68, \n",
            "'o' :  69, \n",
            "'p' :  70, \n",
            "'q' :  71, \n",
            "'r' :  72, \n",
            "'s' :  73, \n",
            "'t' :  74, \n",
            "'u' :  75, \n",
            "'v' :  76, \n",
            "'w' :  77, \n",
            "'x' :  78, \n",
            "'y' :  79, \n",
            "'z' :  80, \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Convertir texto a números"
      ],
      "metadata": {
        "id": "lB6tAN_41W0D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text_as_int = np.array([char2idx[c] for c in text])\n",
        "\n",
        "#Mostrar un parrafo del texto\n",
        "print('text: {}'.format(repr(text[:50])))\n",
        "print('num: {}'.format(repr(text_as_int[:50])))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZMjpfVOA1npY",
        "outputId": "5ec46817-bef7-48fb-9f47-5f345c3835b8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "text: \"TITLE: Alice's Adventures in Wonderland\\nAUTHOR: Le\"\n",
            "num: array([44, 33, 44, 36, 29, 20,  1, 25, 66, 63, 57, 59,  4, 73,  1, 25, 58,\n",
            "       76, 59, 68, 74, 75, 72, 59, 73,  1, 63, 68,  1, 47, 69, 68, 58, 59,\n",
            "       72, 66, 55, 68, 58,  0, 25, 45, 44, 32, 39, 42, 20,  1, 36, 59])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Preparar los datos"
      ],
      "metadata": {
        "id": "MC2tmW5b2aTT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "char_dataset = tf.data.Dataset.from_tensor_slices(text_as_int)\n",
        "\n",
        "\n",
        "seq_length = 100\n",
        "\n",
        "sequences = char_dataset.batch(seq_length+1, drop_remainder=True)"
      ],
      "metadata": {
        "id": "KfUlHzoD2cvF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#comprobar datos\n",
        "for item in sequences.take(10):\n",
        "  print(repr(''.join(idx2char[item.numpy()])))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fWJVR1f33HBz",
        "outputId": "7016d9f2-8889-4b60-817c-94e331894e4e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\"TITLE: Alice's Adventures in Wonderland\\nAUTHOR: Lewis Carroll\\n\\n\\n= CHAPTER I = \\n=( Down the Rabbit-Hol\"\n",
            "'e )=\\n\\n  Alice was beginning to get very tired of sitting by her sister\\non the bank, and of having not'\n",
            "'hing to do:  once or twice she had\\npeeped into the book her sister was reading, but it had no\\npicture'\n",
            "\"s or conversations in it, `and what is the use of a book,'\\nthought Alice `without pictures or convers\"\n",
            "\"ation?'\\n\\n  So she was considering in her own mind (as well as she could,\\nfor the hot day made her fee\"\n",
            "'l very sleepy and stupid), whether\\nthe pleasure of making a daisy-chain would be worth the trouble\\nof'\n",
            "' getting up and picking the daisies, when suddenly a White\\nRabbit with pink eyes ran close by her.\\n\\n '\n",
            "' There was nothing so VERY remarkable in that; nor did Alice\\nthink it so VERY much out of the way to '\n",
            "\"hear the Rabbit say to\\nitself, `Oh dear!  Oh dear!  I shall be late!'  (when she thought\\nit over afte\"\n",
            "'rwards, it occurred to her that she ought to have\\nwondered at this, but at the time it all seemed qui'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Preparar datos de entrenamiento, Entrada de caracter 0-99, Salida de caracter 0-100"
      ],
      "metadata": {
        "id": "zTnmyynm4HnR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def split_input_target(chunk):\n",
        "  input_text = chunk[:-1]\n",
        "  target_text = chunk[1:]\n",
        "  return input_text, target_text\n",
        "\n",
        "dataset = sequences.map(split_input_target)"
      ],
      "metadata": {
        "id": "IpGk8c6-4TEz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Agrupar en batches\n",
        "\n",
        "BATCH_SIZE = 64\n",
        "BUFFER_SIZE = 10000\n",
        "\n",
        "\n",
        "dataset = dataset.shuffle(BUFFER_SIZE).batch(BATCH_SIZE, drop_remainder=True)\n",
        "print(dataset)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "34I9rpmV4yvq",
        "outputId": "f92dc95b-044c-46e3-ed20-1206fa0cfbed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<_BatchDataset element_spec=(TensorSpec(shape=(64, 100), dtype=tf.int64, name=None), TensorSpec(shape=(64, 100), dtype=tf.int64, name=None))>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Modelo"
      ],
      "metadata": {
        "id": "WxSi_YxH5v06"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.src.layers.rnn.lstm_v1 import LSTM\n",
        "def build_model(vocab_size, embedding_dim, rnn_units, batch_size):\n",
        "  model = tf.keras.Sequential([\n",
        "      layers.Embedding(vocab_size, embedding_dim,\n",
        "                       batch_input_shape = [batch_size,None]),\n",
        "      layers.LSTM(rnn_units,\n",
        "                  return_sequences=True,\n",
        "                  stateful=True,\n",
        "                  recurrent_initializer = 'glorot_uniform'),\n",
        "      layers.Dense(vocab_size)\n",
        "  ])\n",
        "  return model"
      ],
      "metadata": {
        "id": "lSIoIO1X5yMr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_size = len(vocab)\n",
        "embedding_dim = 256\n",
        "rnn_units = 1024\n",
        "\n",
        "model = build_model(\n",
        "    vocab_size = vocab_size,\n",
        "    embedding_dim = embedding_dim,\n",
        "    rnn_units = rnn_units,\n",
        "    batch_size = BATCH_SIZE\n",
        ")"
      ],
      "metadata": {
        "id": "YZSBjSDe7yUo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K8VeQ34a8dOv",
        "outputId": "05e86330-a123-4fd2-9c40-e544a1f6ff7a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_4 (Embedding)     (64, None, 256)           20736     \n",
            "                                                                 \n",
            " lstm_4 (LSTM)               (64, None, 1024)          5246976   \n",
            "                                                                 \n",
            " dense_4 (Dense)             (64, None, 81)            83025     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 5350737 (20.41 MB)\n",
            "Trainable params: 5350737 (20.41 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Entrenamiento"
      ],
      "metadata": {
        "id": "4IHXVlRL8pQF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def loss(labels, logits):\n",
        "  return tf.keras.losses.sparse_categorical_crossentropy(labels, logits, from_logits=True)\n",
        "\n",
        "model.compile(optimizer='adam', loss = loss)"
      ],
      "metadata": {
        "id": "d8JsNPbs9Eqz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Checkpoints\n",
        "checkpoint_dir = './training_checkpoints'\n",
        "checkpoint_prefix = os.path.join(checkpoint_dir, 'ckpt_(epoch)')\n",
        "\n",
        "checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
        "    filepath = checkpoint_prefix,\n",
        "    save_weights_only=True\n",
        ")"
      ],
      "metadata": {
        "id": "mlKdSy_n-Uax"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "EPOCHS = 50\n",
        "model.fit(dataset, epochs=EPOCHS, callbacks=[checkpoint_callback])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4ZEbKZ6T9qNT",
        "outputId": "43a827a9-32d8-442e-f8f3-342a465da30a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "22/22 [==============================] - 4s 97ms/step - loss: 3.3287\n",
            "Epoch 2/50\n",
            "22/22 [==============================] - 2s 83ms/step - loss: 3.0384\n",
            "Epoch 3/50\n",
            "22/22 [==============================] - 2s 88ms/step - loss: 2.7322\n",
            "Epoch 4/50\n",
            "22/22 [==============================] - 2s 75ms/step - loss: 2.4624\n",
            "Epoch 5/50\n",
            "22/22 [==============================] - 2s 70ms/step - loss: 2.2782\n",
            "Epoch 6/50\n",
            "22/22 [==============================] - 2s 75ms/step - loss: 2.1371\n",
            "Epoch 7/50\n",
            "22/22 [==============================] - 2s 76ms/step - loss: 2.0182\n",
            "Epoch 8/50\n",
            "22/22 [==============================] - 2s 81ms/step - loss: 1.9217\n",
            "Epoch 9/50\n",
            "22/22 [==============================] - 2s 72ms/step - loss: 1.8354\n",
            "Epoch 10/50\n",
            "22/22 [==============================] - 2s 73ms/step - loss: 1.7522\n",
            "Epoch 11/50\n",
            "22/22 [==============================] - 2s 73ms/step - loss: 1.6789\n",
            "Epoch 12/50\n",
            "22/22 [==============================] - 2s 74ms/step - loss: 1.6087\n",
            "Epoch 13/50\n",
            "22/22 [==============================] - 2s 73ms/step - loss: 1.5499\n",
            "Epoch 14/50\n",
            "22/22 [==============================] - 2s 73ms/step - loss: 1.4920\n",
            "Epoch 15/50\n",
            "22/22 [==============================] - 2s 77ms/step - loss: 1.4334\n",
            "Epoch 16/50\n",
            "22/22 [==============================] - 2s 73ms/step - loss: 1.3779\n",
            "Epoch 17/50\n",
            "22/22 [==============================] - 2s 79ms/step - loss: 1.3268\n",
            "Epoch 18/50\n",
            "22/22 [==============================] - 2s 73ms/step - loss: 1.2778\n",
            "Epoch 19/50\n",
            "22/22 [==============================] - 2s 71ms/step - loss: 1.2275\n",
            "Epoch 20/50\n",
            "22/22 [==============================] - 2s 88ms/step - loss: 1.1857\n",
            "Epoch 21/50\n",
            "22/22 [==============================] - 2s 77ms/step - loss: 1.1369\n",
            "Epoch 22/50\n",
            "22/22 [==============================] - 2s 73ms/step - loss: 1.0874\n",
            "Epoch 23/50\n",
            "22/22 [==============================] - 2s 73ms/step - loss: 1.0405\n",
            "Epoch 24/50\n",
            "22/22 [==============================] - 2s 74ms/step - loss: 0.9891\n",
            "Epoch 25/50\n",
            "22/22 [==============================] - 2s 77ms/step - loss: 0.9446\n",
            "Epoch 26/50\n",
            "22/22 [==============================] - 2s 77ms/step - loss: 0.8935\n",
            "Epoch 27/50\n",
            "22/22 [==============================] - 2s 74ms/step - loss: 0.8423\n",
            "Epoch 28/50\n",
            "22/22 [==============================] - 2s 73ms/step - loss: 0.7938\n",
            "Epoch 29/50\n",
            "22/22 [==============================] - 2s 74ms/step - loss: 0.7474\n",
            "Epoch 30/50\n",
            "22/22 [==============================] - 2s 74ms/step - loss: 0.6934\n",
            "Epoch 31/50\n",
            "22/22 [==============================] - 2s 73ms/step - loss: 0.6431\n",
            "Epoch 32/50\n",
            "22/22 [==============================] - 2s 78ms/step - loss: 0.5996\n",
            "Epoch 33/50\n",
            "22/22 [==============================] - 2s 80ms/step - loss: 0.5626\n",
            "Epoch 34/50\n",
            "22/22 [==============================] - 2s 75ms/step - loss: 0.5202\n",
            "Epoch 35/50\n",
            "22/22 [==============================] - 2s 74ms/step - loss: 0.4795\n",
            "Epoch 36/50\n",
            "22/22 [==============================] - 2s 73ms/step - loss: 0.4503\n",
            "Epoch 37/50\n",
            "22/22 [==============================] - 2s 78ms/step - loss: 0.4211\n",
            "Epoch 38/50\n",
            "22/22 [==============================] - 2s 75ms/step - loss: 0.3925\n",
            "Epoch 39/50\n",
            "22/22 [==============================] - 2s 84ms/step - loss: 0.3737\n",
            "Epoch 40/50\n",
            "22/22 [==============================] - 2s 75ms/step - loss: 0.3548\n",
            "Epoch 41/50\n",
            "22/22 [==============================] - 2s 80ms/step - loss: 0.3388\n",
            "Epoch 42/50\n",
            "22/22 [==============================] - 2s 75ms/step - loss: 0.3183\n",
            "Epoch 43/50\n",
            "22/22 [==============================] - 2s 78ms/step - loss: 0.3048\n",
            "Epoch 44/50\n",
            "22/22 [==============================] - 2s 74ms/step - loss: 0.2941\n",
            "Epoch 45/50\n",
            "22/22 [==============================] - 2s 75ms/step - loss: 0.2884\n",
            "Epoch 46/50\n",
            "22/22 [==============================] - 2s 75ms/step - loss: 0.2786\n",
            "Epoch 47/50\n",
            "22/22 [==============================] - 2s 85ms/step - loss: 0.2684\n",
            "Epoch 48/50\n",
            "22/22 [==============================] - 2s 75ms/step - loss: 0.2595\n",
            "Epoch 49/50\n",
            "22/22 [==============================] - 2s 79ms/step - loss: 0.2561\n",
            "Epoch 50/50\n",
            "22/22 [==============================] - 2s 75ms/step - loss: 0.2481\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7ca315dc4670>"
            ]
          },
          "metadata": {},
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Generación de texto"
      ],
      "metadata": {
        "id": "MMKZ91blAr86"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = build_model(vocab_size, embedding_dim, rnn_units, batch_size = 1)\n",
        "\n",
        "model.load_weights(tf.train.latest_checkpoint(checkpoint_dir))\n",
        "\n",
        "model.build(tf.TensorShape([1,None]))"
      ],
      "metadata": {
        "id": "HMFIW-2YAx2_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_text(model, start_string, temp=0.5):\n",
        "  num_generate = 500\n",
        "\n",
        "  input_eval = [char2idx[s] for s in start_string]\n",
        "\n",
        "  input_eval = tf.expand_dims(input_eval, 0)\n",
        "\n",
        "  text_generated = []\n",
        "\n",
        "  temperature = temp\n",
        "\n",
        "  model.reset_states()\n",
        "\n",
        "  for i in range(num_generate):\n",
        "    predictions = model(input_eval)\n",
        "\n",
        "    predictions = tf.squeeze(predictions,0)\n",
        "\n",
        "    predictions = predictions/temperature\n",
        "    predicted_id = tf.random.categorical(predictions, num_samples=1)[-1,0].numpy()\n",
        "\n",
        "    input_eval = tf.expand_dims([predicted_id],0)\n",
        "\n",
        "    text_generated.append(idx2char[predicted_id])\n",
        "\n",
        "  return(start_string + ''.join(text_generated))"
      ],
      "metadata": {
        "id": "mPt7vPUeBTrG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Resultados con una temperatura de 0.5"
      ],
      "metadata": {
        "id": "KgQ-cBjZYgIR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(generate_text(model, start_string=u\"cat\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TgUiNOsREcWL",
        "outputId": "1f5d899b-4646-46fe-93c8-051420504e3a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cat; `You're to go down the chimney?--Nay, I shan't! YOU do next!  You're a very poor than read as fellows\n",
            "done down!'\n",
            "\n",
            "  So she stood looking at the house, and\n",
            "wondering what to do this, and as she was now about a thought to this\n",
            "morent that she went on parting that it on his spectacles.  `Where shall I begin,\n",
            "please your Majesty?' he asked.\n",
            "\n",
            "  `Yes, that's it,' said the Queen, `and that's the\n",
            "jury--'\n",
            "\n",
            "  `If the rose-tree, and went on so long that said anything more times and mouths so VERY wide, \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(generate_text(model, start_string=u\"emotion\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oibL2PnOUb_W",
        "outputId": "43719f03-a420-4d36-bf8d-a6ea9cb0d124"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "emotions out of its\n",
            "mouth, and its great eyes half shut.\n",
            "\n",
            "  This seemed to Alice a good opportunity for many more than think, and managed to put it into one of the cupboards as she\n",
            "fell past it.\n",
            "\n",
            "  `Well!' thought Alice to herself, `in my\n",
            "going to do:  They hed the words don't FIT you,' said the King, looking round\n",
            "the court with a smile.  `That's Bill,'\n",
            "thought Alice,) `Well, I hardly know--No more, thank ye; I'm\n",
            "better now--but I know what to beautify is,\n",
            "I suppose it only one knee say there was no o\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Resultados con temperatura = 0.3"
      ],
      "metadata": {
        "id": "yI06oW7wYk06"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(generate_text(model, start_string=u\"cat\", temp = 0.3))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "voFNbYOQYnky",
        "outputId": "8de3c75e-0a29-4eed-a8f3-006a33de6971"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cat her\n",
            "lips and staring at the\n",
            "Hatter, and, just as the Dormouse crossed the court, she said to\n",
            "one of the officers of the court.'\n",
            "\n",
            "  Alice did not at all like the tone of this remark, and thought\n",
            "it would be as well as presched her.  `Oh, I should like to have it explain it is the door as herself, to see if she could have been changed for Mabel!  I'll try and say \"How doth the little--\"'\n",
            "and she crossed her hands of tears, but she stremped to her the party.\n",
            "Some of the birds hurried off at once: \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(generate_text(model, start_string=u\"emotion\", temp = 0.3))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tr2wKKPeZG1e",
        "outputId": "6a1169c8-0a8e-4475-f55b-d92248a59b91"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "emotions out of its\n",
            "mouth, and its great eyes half shut.\n",
            "\n",
            "  This seemed to Alice a good opportunity for many more than the whiting,' said the Mock Turtle, `they--you've\n",
            "seen them, of course?'\n",
            "\n",
            "  `Yes,' said Alice, `we learned your the reason and all\n",
            "that,' he said to the Gryphon.\n",
            "\n",
            "  `The reason is, that's a bottle marked out again.\n",
            "\n",
            "  `Mean to you to see the Mock Turtle, and to hear his history.  I have bany the ten such a pleasant temper, and\n",
            "thought to herself that perhaps it was only the pepper that\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Resultados con temperatura = 0.9"
      ],
      "metadata": {
        "id": "L_ZzCuTJZNUA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(generate_text(model, start_string=u\"cat\", temp = 0.9))"
      ],
      "metadata": {
        "id": "h871BoArZSWs",
        "outputId": "4561ee5c-f5f2-4f57-c643-1522cd9609bb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cat sit;\n",
            "`whencr Alice did not quite dnow why they Warng along the table, but there was nothing on it\n",
            "but the time They were thing,' the King said to the Hatter.\n",
            "\n",
            "  `No, no!' said the Queen, to VERY Grapper, `But thongure so many to the sears of her head.\n",
            "\n",
            "  `Yes, I'm a player somerotm, or condingin.'\n",
            "\n",
            "  `Hadn, it had must be only,' said the Caterpillar.\n",
            "\n",
            "  `Well, perhaps your feelings may be different,' said the King in a very dry longer; `but, if you want to be?'\n",
            "\n",
            "  `It is a very good height ind \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(generate_text(model, start_string=u\"emotion\", temp = 0.9))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fY0re_RbZMzO",
        "outputId": "c3d1123b-81b3-47ac-89e8-defbc11608d8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "emotions one of the Sould, and\n",
            "aboved the words `DRING Me,'\n",
            "Alice rad Alice like the roof.\n",
            "\n",
            "  `Of the mushroommomy,' hard\n",
            "the Mock Turtle ran with langered to be tlates.)\n",
            "\n",
            "  `No, no!' said the Queen, who must began any anxiously to the jury, who in the world `Chese at all him There was near enought it, you know.  Coll her fan and st\n",
            "again.\n",
            "\n",
            "  `Oh, I'm a porat ell, one Alice appeared, she was out of sight: before the ot of be the whole she thought it mose by the time when\n",
            "then the game was in mark Turtl\n"
          ]
        }
      ]
    }
  ]
}